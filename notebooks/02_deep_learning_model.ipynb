{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame head:\n",
      "                                file_path  genre\n",
      "0  ..\\datasets\\GTZAN\\blues\\blues.00000.au  blues\n",
      "1  ..\\datasets\\GTZAN\\blues\\blues.00001.au  blues\n",
      "2  ..\\datasets\\GTZAN\\blues\\blues.00002.au  blues\n",
      "3  ..\\datasets\\GTZAN\\blues\\blues.00003.au  blues\n",
      "4  ..\\datasets\\GTZAN\\blues\\blues.00004.au  blues\n",
      "Total files: 1000\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('..', 'datasets', 'GTZAN')  \n",
    "genres = os.listdir(data_path)\n",
    "\n",
    "file_paths = []\n",
    "for genre in genres:\n",
    "    genre_folder = os.path.join(data_path, genre)\n",
    "    if not os.path.isdir(genre_folder):\n",
    "        continue\n",
    "    for file_name in os.listdir(genre_folder):\n",
    "        if file_name.endswith('.au'):  \n",
    "            file_paths.append({\n",
    "                'file_path': os.path.join(genre_folder, file_name),\n",
    "                'genre': genre\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(file_paths)\n",
    "print(\"DataFrame head:\")\n",
    "print(df.head())\n",
    "print(\"Total files:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "    def __init__(self, df, sr=22050, duration=10, n_mels=128, fixed_length=128, transform=None):\n",
    "        \"\"\"\n",
    "        df: DataFrame with columns 'file_path' and 'genre'\n",
    "        sr: sampling rate\n",
    "        duration: seconds to load from each audio file\n",
    "        n_mels: number of Mel bands\n",
    "        fixed_length: fixed number of time frames for spectrogram (will pad/truncate)\n",
    "        transform: any additional transforms (if needed)\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.sr = sr\n",
    "        self.duration = duration\n",
    "        self.n_mels = n_mels\n",
    "        self.fixed_length = fixed_length\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Encode labels\n",
    "        self.le = LabelEncoder()\n",
    "        self.df['genre_encoded'] = self.le.fit_transform(self.df['genre'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        file_path = row['file_path']\n",
    "        label = row['genre_encoded']\n",
    "        \n",
    "        # Load audio (duration seconds)\n",
    "        y, sr = librosa.load(file_path, sr=self.sr, duration=self.duration)\n",
    "        \n",
    "        # Compute mel spectrogram\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=self.n_mels)\n",
    "        # Convert power spectrogram (amplitude squared) to decibel (log scale)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        # Fix time dimension: pad or truncate along axis=1\n",
    "        if S_db.shape[1] < self.fixed_length:\n",
    "            S_db = librosa.util.fix_length(S_db, size=self.fixed_length, axis=1)\n",
    "        else:\n",
    "            S_db = S_db[:, :self.fixed_length]\n",
    "        \n",
    "        # Add channel dimension (for CNN: (1, n_mels, fixed_length))\n",
    "        S_db = np.expand_dims(S_db, axis=0)\n",
    "        # Convert to torch tensor\n",
    "        S_db = torch.tensor(S_db, dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            S_db = self.transform(S_db)\n",
    "            \n",
    "        return S_db, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 800\n",
      "Number of validation samples: 200\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame into train and validation (80/20)\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42, stratify=df['genre'])\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = GTZANDataset(df_train, duration=10, fixed_length=128)\n",
    "val_dataset = GTZANDataset(df_val, duration=10, fixed_length=128)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of validation samples:\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10, learning_rate=1e-3):\n",
    "        super(MusicClassifier, self).__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Define a simple CNN architecture\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # input: (1, n_mels, fixed_length)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2)  # halves both dimensions\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Calculate flattened feature size:\n",
    "        # Input shape: (1, 128, 128) -> after pool1: (16, 64, 64)\n",
    "        # after pool2: (32, 32, 32)\n",
    "        # after pool3: (64, 16, 16)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name  | Type        | Params | Mode \n",
      "-----------------------------------------------\n",
      "0  | conv1 | Conv2d      | 160    | train\n",
      "1  | bn1   | BatchNorm2d | 32     | train\n",
      "2  | pool1 | MaxPool2d   | 0      | train\n",
      "3  | conv2 | Conv2d      | 4.6 K  | train\n",
      "4  | bn2   | BatchNorm2d | 64     | train\n",
      "5  | pool2 | MaxPool2d   | 0      | train\n",
      "6  | conv3 | Conv2d      | 18.5 K | train\n",
      "7  | bn3   | BatchNorm2d | 128    | train\n",
      "8  | pool3 | MaxPool2d   | 0      | train\n",
      "9  | fc1   | Linear      | 2.1 M  | train\n",
      "10 | fc2   | Linear      | 1.3 K  | train\n",
      "-----------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.488     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088f7fd6bb194f9ca5dadfce8af5dd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\OneDrive\\Documents\\music-genre-classification-and-recommendation\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\sachi\\OneDrive\\Documents\\music-genre-classification-and-recommendation\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fbf83347bf4197b5d638164bcbfedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e86a55a7c748608afe1d8d4df91c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72098a8f7c224e8b8777c8e2d4475712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f99e895dda7431898ed8b0fe4085cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b63f7981a984e7792c4532bed28dfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae88cf0807640c687a40e9bc2466fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55bae2892e34b16af76e72c8eb55e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4d9b7ffbff4eb7970b0d19e3a9e1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e5051e708b4ea5a049871d4fa78a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479c70e35d08495db5d7853f0abfd81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf44f4338294e2da79f107bd0b3264b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "num_classes = 10  # GTZAN has 10 genres\n",
    "model = MusicClassifier(num_classes=num_classes, learning_rate=1e-3)\n",
    "\n",
    "# Create a PyTorch Lightning Trainer (use GPU if available)\n",
    "trainer = Trainer(max_epochs=10, accelerator=\"auto\", devices=\"auto\")\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386bce99608641538ed4e0f2450e655c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.6100000143051147\n",
      "        val_loss            1.5067682266235352\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'val_loss': 1.5067682266235352, 'val_acc': 0.6100000143051147}]\n"
     ]
    }
   ],
   "source": [
    "# Run validation and print out the accuracy\n",
    "results = trainer.validate(model, dataloaders=val_loader)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
